{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperability Insight into OPT models\n",
    "Tests to see if it is possible to remove coding ability from Meta OPT model for different scales.\n",
    "Current methods are:\n",
    "- look at activation frequency of MLP mid layers\n",
    "- Look at 'crossover threshold' of Attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "try: # if in google colab, download necessary python files\n",
    "  import google.colab \n",
    "  ! git clone https://github.com/pesvut/opt-tools.git && mv ./opt-tools/src/*.py .\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "! pip3 install -qqr requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from model import Model\n",
    "from texts import prepare\n",
    "from activations import prune_and_evaluate, evaluate_all, init_data_dict\n",
    "\n",
    "# df.append has FutureWarning, here is the alternative\n",
    "def append( df: pd.DataFrame, data: dict ):\n",
    "    wandb.log(data)\n",
    "    data = pd.DataFrame({ k:[v] for k,v in data.items() })\n",
    "    return pd.concat([ df, data ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Configure initial model and tests\n",
    "model_size, token_limit  = \"125m\", 1000\n",
    "run_pre_test             = True\n",
    "pre_removals = []\n",
    "\n",
    "# Removals parameters\n",
    "ff_frac,   ff_eps   = 0.02, 0.001\n",
    "attn_frac           = 0.01\n",
    "cripple, focus      = \"code\", \"pile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qxlqkkvl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-firecracker-3</strong> at: <a href=\"https://wandb.ai/soft-opt/seperability-code-pile/runs/qxlqkkvl\" target=\"_blank\">https://wandb.ai/soft-opt/seperability-code-pile/runs/qxlqkkvl</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_220104-qxlqkkvl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qxlqkkvl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706c197761484bd498bd136d2b53c15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670712633640505, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/seperability/src/wandb/run-20230202_220125-cux0tpfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/soft-opt/seperability-code-pile/runs/cux0tpfl\" target=\"_blank\">enchanting-rocket-4</a></strong> to <a href=\"https://wandb.ai/soft-opt/seperability-code-pile\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/soft-opt/seperability-code-pile\" target=\"_blank\">https://wandb.ai/soft-opt/seperability-code-pile</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/soft-opt/seperability-code-pile/runs/cux0tpfl\" target=\"_blank\">https://wandb.ai/soft-opt/seperability-code-pile/runs/cux0tpfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded OPT-125m\n",
      " - Registered 12 OPT Attention Layers\n"
     ]
    }
   ],
   "source": [
    "# Prepare data logging\n",
    "wandb.init(project=\"seperability-code-pile\")\n",
    "c = wandb.config\n",
    "c.update({\n",
    "    \"model_size\"  : model_size,\n",
    "    \"token_limit\" : token_limit,\n",
    "    \"run_pre_test\": run_pre_test,\n",
    "    \"ff_frac\"  : ff_frac,\n",
    "    \"ff_eps\"   : ff_eps,\n",
    "    \"attn_frac\": attn_frac,\n",
    "    \"cripple\": cripple,\n",
    "    \"focus\"  : focus,\n",
    "})\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Load model and show details about model\n",
    "opt = Model( c.model_size, limit=c.token_limit )\n",
    "\n",
    "# Pre-pruning of model\n",
    "opt.delete_ff_keys_from_files(pre_removals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration EleutherAI--the_pile_deduplicated-40e90bd48c49557b\n",
      "Acc: 72.93|44.97 (Skip: 60.72|34.49): : 10096it [00:08, 1162.16it/s]                          \n",
      "Using custom data configuration codeparrot--codeparrot-clean-valid-826c6fd8b27e5523\n",
      "Acc: 79.51|60.27 (Skip: 63.43|42.91): : 10209it [00:07, 1282.54it/s]                          \n"
     ]
    }
   ],
   "source": [
    "# Evaluate model before removal of any neurons\n",
    "if c.run_pre_test:\n",
    "    data = init_data_dict()\n",
    "    data.update( evaluate_all( opt, 1e5 ) )\n",
    "    df = append( df, data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration EleutherAI--the_pile_deduplicated-40e90bd48c49557b\n",
      "100311it [01:35, 1050.61it/s]                             \n",
      "Using custom data configuration codeparrot--codeparrot-clean-valid-826c6fd8b27e5523\n",
      "  2%|▏         | 2000/100000.0 [00:02<01:47, 909.67it/s]"
     ]
    }
   ],
   "source": [
    "# First do some pruning of the feed forward layers\n",
    "for i in range(3):\n",
    "    data = prune_and_evaluate( opt, c.ff_frac, c.attn_frac, c.ff_eps, cripple=c.cripple, focus=c.focus )\n",
    "    df = append( df, data )\n",
    "print(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Next do some pruning of the feed forward layers + attention layers\n",
    "for i in range(3):\n",
    "    data = prune_and_evaluate( opt, c.ff_frac, c.attn_frac, c.ff_eps, cripple=c.cripple, focus=c.focus )\n",
    "    df = append( df, data )\n",
    "print(df.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "caa55a89e6d7ad9e85de7c571769c816c820344d6fb9c860a740c7fc03f95f43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
