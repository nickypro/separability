{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # if in google colab, download necessary python files\n",
    "  import google.colab\n",
    "  ! git clone https://github.com/pesvut/opt-tools.git && mv ./opt-tools/src/*.py .\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "! pip install -qq transformers datasets evaluate zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from texts import prepare_pile, prepare_code\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare( dataset_name ):\n",
    "    if dataset_name == 'pile':\n",
    "        return prepare_pile()\n",
    "    if dataset_name == 'code':\n",
    "        return prepare_code()\n",
    "\n",
    "opt = Model(\"125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( opt.model.decoder.layers[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def setup_counter(ff_keys):\n",
    "    shape = ff_keys.size()\n",
    "    counter = []\n",
    "    for i in range(shape[0]):\n",
    "        counter.append( torch.zeros( shape[-1]))\n",
    "    return torch.stack(counter).to( opt.device )\n",
    "\n",
    "def count_keys( dataset_name, limit=1000, sample_size=10000, num_samples=1, \n",
    "                check_accuracy=False, k=10, check_skips=False ):\n",
    "    dataset, label, skip_eval = prepare( dataset_name )\n",
    "    counters = []\n",
    "    counter = None\n",
    "    curr_count = 0\n",
    "    with tqdm(total=sample_size*num_samples) as pbar:\n",
    "        for data in dataset:\n",
    "            text = data[label]\n",
    "            input_ids = opt.get_ids( text, limit=limit )\n",
    "            ids = input_ids.squeeze().detach().cpu()\n",
    "\n",
    "            # Criteria for counting the token activation\n",
    "            criteria = torch.ones_like( ids, dtype=torch.bool )\n",
    "\n",
    "            # check if prediction is accurate enough to count\n",
    "            if check_accuracy:\n",
    "                residual_stream = opt.get_residual_stream( input_ids=input_ids )\n",
    "                logits = opt.unembed( residual_stream[-1] ).detach().cpu()\n",
    "                top_k_tokens = opt.top_k_tokens( logits, k=k ).squeeze()\n",
    "\n",
    "                for index in range(len(ids)-1):\n",
    "                    criteria[index] *= (ids[index+1] in top_k_tokens[index])\n",
    "\n",
    "            # Choose a set of token ids to skip \n",
    "            if check_skips:\n",
    "                skip_ids = set()\n",
    "                for skip_string in skip_eval:\n",
    "                    skip_id = int( opt.get_ids( skip_string ).squeeze()[-1] )\n",
    "                    skip_ids.add( skip_id )\n",
    "\n",
    "                for index in range(len(ids)-1):\n",
    "                    criteria[index] *= (ids[index+1] in skip_ids)\n",
    "                \n",
    "            num_valid_tokens = criteria.sum()\n",
    "            curr_count += num_valid_tokens\n",
    "\n",
    "            ff_keys = opt.get_ff_key_activations(input_ids=input_ids)\n",
    "            if counter is None:\n",
    "                counter = setup_counter(ff_keys)\n",
    "            \n",
    "            for layer_index, layer in enumerate(ff_keys):\n",
    "                for token_index, key_activation in enumerate(layer):\n",
    "                    if not criteria[token_index]:\n",
    "                        continue\n",
    "                    counter[layer_index] += ( key_activation != 0 )\n",
    "\n",
    "\n",
    "            pbar.update( int(num_valid_tokens) )\n",
    "            if curr_count > sample_size:\n",
    "                counter = counter / curr_count\n",
    "                counters.append( counter.detach().cpu() )\n",
    "                print( f'sample {len(counters)}: {curr_count}' )\n",
    "                \n",
    "                counter = setup_counter(ff_keys)\n",
    "                curr_count = 0\n",
    "            \n",
    "            if len( counters ) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    return torch.stack( counters )\n",
    "\n",
    "def acc_str( acc, pred ):\n",
    "    percentage = (100*round(acc/pred, 3))\n",
    "    return \"%.1f\"%percentage + \"% - ( {acc}/{pred} )\"\n",
    "\n",
    "def evaluate( dataset_name, limit : int = 1e6 ):\n",
    "    dataset, label, skip_eval = prepare( dataset_name )\n",
    "    out = opt.evaluate_dataset( dataset, token_limit=1000, k=1,\n",
    "        start_index=1, stopping_index=limit, skip_eval=skip_eval,\n",
    "        dataset_text_label=label, count_tokens=False )\n",
    "    print( f'{dataset_name} w/ skip:', \n",
    "        acc_str(out['num_skip_accurate'], out['num_skip_predictions']) )\n",
    "    print( f'{dataset_name} no skip:',\n",
    "        acc_str( out['num_accurate'], out['num_predictions']) )\n",
    "    return out\n",
    "\n",
    "def evaluate_all( limit: int = 1e5 ):\n",
    "    pile_out = evaluate( 'pile', limit )\n",
    "    code_out = evaluate( 'code', limit )\n",
    "\n",
    "def delete_and_evaluate(\n",
    "        freq_multiple: float,\n",
    "        counter_sample_size: int = 5e4,\n",
    "        eval_sample_size: int = 1e5,\n",
    "        ):\n",
    "    # Count activation of MLP middle layers\n",
    "    pile_counters = count_keys( 'pile', sample_size=counter_sample_size, num_samples=1, check_accuracy=True )\n",
    "    code_counters = count_keys( 'code', sample_size=counter_sample_size, num_samples=1, check_accuracy=True )\n",
    "    \n",
    "    # Delete when the MLP layer activates way more for code than pile\n",
    "    ff_criterion = ( code_counters[0] > (freq_multiple*pile_counters[0]) )\n",
    "    sums = [ x.sum() for x in ff_criterion.detach().numpy() ]\n",
    "    print( \"%5d -\"%np.sum(sums), sums )\n",
    "    opt.delete_ff_keys( ff_criterion )\n",
    "    \n",
    "    # See the effect this has on performance\n",
    "    evaluate_all( eval_sample_size )\n",
    "\n",
    "    try:\n",
    "        # Save the indices that were deleted into the timestamped file\n",
    "        now = datetime.datetime.now().strftime( \"%Y-%m-%d_%H:%M:%S\" )\n",
    "        filename = f'tmp/{opt.model_size}-{freq_multiple}x-{now}.npy'\n",
    "        os.makedirs( 'tmp', exist_ok=True )\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.save(f, ff_criterion)\n",
    "    except:\n",
    "        print(\"Did not save sadly :(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criteria = np.array( [[True, False, True],[True,False,False]], dtype=int )\n",
    "now = datetime.datetime.now().strftime( \"%Y-%m-%d_%H:%M:%S\" )\n",
    "filename = f'tmp/{opt.model_size}-{1000}x-{now}.npy'\n",
    "os.makedirs( 'tmp', exist_ok=True )\n",
    "with open(filename, 'wb') as f:\n",
    "    np.save(f, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model before removal of any neurons\n",
    "evaluate_all( 1e5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    delete_and_evaluate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#for layer in range(len(code_counters[0])):\n",
    "#    plt.figure()\n",
    "#    subsample = 1000\n",
    "#    plt.plot(code_counters[0][layer][:subsample], color='red', linewidth=0.2)\n",
    "#    plt.plot(pile_counters[0][layer][:subsample], color='blue', linewidth=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 1e4 steps\n",
    "```\n",
    "pile w/ skip: 39.0% - ( 4022/10381 )\n",
    "pile no skip: 49.0% - ( 8109/16445 )\n",
    "\n",
    "code w/ skip: 43.0% - ( 4381/10209 )\n",
    "code no skip: 60.0% - ( 12974/21528)\n",
    "```\n",
    "\n",
    "After 1 iteration:\n",
    "```\n",
    "pile w/ skip: 36.0% - ( 3702/10381 )\n",
    "pile no skip: 46.0% - ( 7573/16445 )\n",
    "\n",
    "code w/ skip: 35.0% - ( 3620/10209 )\n",
    "code no skip: 50.0% - ( 10818/21528 )\n",
    "```\n",
    "\n",
    "After 3 iterations:\n",
    "```\n",
    "pile w/ skip: 31.0% - ( 3249/10381 )\n",
    "pile no skip: 43.0% - ( 7007/16445 )\n",
    "\n",
    "code w/ skip: 21.0% - ( 2108/10209 )\n",
    "code no skip: 37.0% - ( 7970/21528 )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
