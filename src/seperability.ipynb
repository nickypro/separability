{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # if in google colab, download necessary python files\n",
    "  import google.colab\n",
    "  ! git clone https://github.com/pesvut/opt-tools.git && mv ./opt-tools/src/*.py .\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "! pip install -qq transformers datasets evaluate zstandard welford einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from texts import prepare\n",
    "from activations import calculate_attn_crossover, \\\n",
    "    delete_ff_and_evaluate, evaluate_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded OPT-125m\n",
      " - Registered 12 OPT Attention Layers\n",
      "layers: 12 embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "opt = Model(\"125m\", limit=1000)\n",
    "print( \"layers:\", opt.n_layers, \"embedding dimension:\", opt.d_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0da59c5ddb64b88a784d8d810262269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile loss: 2.9551413443780707\n",
      "pile no skip: 49.31 %\n",
      "pile w/ skip: 24.46 %\n",
      "pile no skip top10: 75.31 %\n",
      "pile w/ skip top10: 63.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-826c6fd8b27e5523\n",
      "Found cached dataset json (/config/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-826c6fd8b27e5523/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2159de65b39a4edda1a8b2b4850d85d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52da3c45d50d4e07a23ed42d5c98ad52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code loss: 2.3737670137332034\n",
      "code no skip: 60.27 %\n",
      "code w/ skip: 20.35 %\n",
      "code no skip top10: 79.51 %\n",
      "code w/ skip top10: 63.43 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pile_base': 49.30982061416844,\n",
       " 'pile_topk': 75.31164487686227,\n",
       " 'pile_skip': 24.457281848586195,\n",
       " 'pile_topk_skip': 63.81851459396975,\n",
       " 'code_base': 60.265700483091784,\n",
       " 'code_topk': 79.50575994054255,\n",
       " 'code_skip': 20.35024154589372,\n",
       " 'code_topk_skip': 63.43422470369282,\n",
       " 'pile_loss': array(2.95514134),\n",
       " 'code_loss': array(2.37376701)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_all( opt, 1e4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156cf105db424fe396eec62e4215835f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-826c6fd8b27e5523\n",
      "Found cached dataset json (/config/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-826c6fd8b27e5523/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff73ab0d3cb345ceb58ff1f59c432fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e36748cda14727b1e7a2a09f60b0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pile_means', 'pile_pos', 'pile_neg', 'code_means', 'code_pos', 'code_neg', 'crossover_multiple', 'removals'])\n"
     ]
    }
   ],
   "source": [
    "attn_data = calculate_attn_crossover(opt, 1.6, sample_size=1e5)\n",
    "print( attn_data.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the attn_data\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow( attn_data['removals'] )\n",
    "ax[1].imshow( np.log2(attn_data['crossover_multiple']) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(pile_means[9][0][49])\n",
    "    print(pile_pos[9][0][49])\n",
    "    print(pile_neg[9][0][49])\n",
    "\n",
    "    rel = (pile_pos.flatten()+1e-5) / np.abs(pile_neg.flatten()-1e-5)\n",
    "    indices = np.argsort( rel )\n",
    "    plt.hlines( y=0, xmin=0, xmax=len(indices), color='black', linestyle=':', linewidth=0.2 )\n",
    "    plt.plot( pile_means.flatten()[indices], linewidth=1)\n",
    "    plt.plot( pile_pos.flatten()[indices]  , linewidth=0.2 )\n",
    "    plt.plot( pile_neg.flatten()[indices]  , linewidth=0.2 )\n",
    "    plt.plot( np.log2(rel[indices])/40, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(12):\n",
    "    break\n",
    "    head = 0\n",
    "    plt.figure()\n",
    "    plt.title(f'Layer {layer} Head {head}')\n",
    "    plt.semilogy( np.abs(pile_neg[layer][head]), base=2 )\n",
    "    plt.semilogy( pile_pos[layer][head], base=2 )\n",
    "    plt.semilogy( np.abs(code_neg[layer][head]), ':', base=2)\n",
    "    plt.semilogy( code_pos[layer][head], ':', base=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1148 - [79, 143, 147, 88, 132, 132, 67, 70, 66, 102, 122]\n"
     ]
    }
   ],
   "source": [
    "pre_removals = [\"tmp/125m-ff-2x-criterion_2022-11-30_16:29:53.npy\"]\n",
    "opt.delete_ff_keys_from_files(pre_removals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4234c1f78572447090593e62daf5bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile loss: 3.3249178903619043\n",
      "pile no skip: 44.39 %\n",
      "pile w/ skip: 21.54 %\n",
      "pile no skip top10: 71.51 %\n",
      "pile w/ skip top10: 59.08 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-826c6fd8b27e5523\n",
      "Found cached dataset json (/config/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-826c6fd8b27e5523/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb10d6233f54536af2b65233b84410e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22b8049d8584aa1bc01e64a5036517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# Evaluate model before removal of any neurons\n",
    "data = evaluate_all( opt, 1e5 )\n",
    "df = df.append( data, ignore_index=True )\n",
    "print( df.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- RUNNING RUN No 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b58af3c10845c28c0b049975b66fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m- RUNNING RUN No\u001b[39m\u001b[39m'\u001b[39m, i )\n\u001b[0;32m----> 5\u001b[0m     data \u001b[39m=\u001b[39m delete_ff_and_evaluate( opt, FREQ_MULTIPLE )\n\u001b[1;32m      6\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mappend( data, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m )\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m( df\u001b[39m.\u001b[39mT )\n",
      "File \u001b[0;32m~/workspace/opt_tools/src/activations.py:334\u001b[0m, in \u001b[0;36mdelete_ff_and_evaluate\u001b[0;34m(opt, freq_multiple, counter_sample_size, eval_sample_size)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete_ff_and_evaluate\u001b[39m(\n\u001b[1;32m    328\u001b[0m         opt: Model,\n\u001b[1;32m    329\u001b[0m         freq_multiple: \u001b[39mfloat\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m         ):\n\u001b[1;32m    333\u001b[0m     \u001b[39m# Count activation of MLP middle layers\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     pile_counters \u001b[39m=\u001b[39m count_ff_key_activations( opt, \u001b[39m'\u001b[39;49m\u001b[39mpile\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    335\u001b[0m         sample_size\u001b[39m=\u001b[39;49mcounter_sample_size, num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, check_accuracy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m )\n\u001b[1;32m    336\u001b[0m     code_counters \u001b[39m=\u001b[39m count_ff_key_activations( opt, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    337\u001b[0m         sample_size\u001b[39m=\u001b[39mcounter_sample_size, num_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, check_accuracy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m )\n\u001b[1;32m    339\u001b[0m     \u001b[39m# Delete when the MLP layer activates way more for code than pile\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/opt_tools/src/activations.py:271\u001b[0m, in \u001b[0;36mcount_ff_key_activations\u001b[0;34m(opt, dataset_name, sample_size, token_limit, num_samples, check_accuracy, k, check_skips)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m# check if prediction is accurate enough to count\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m check_accuracy:\n\u001b[0;32m--> 271\u001b[0m     residual_stream \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mget_residual_stream( input_ids\u001b[39m=\u001b[39;49minput_ids )\n\u001b[1;32m    272\u001b[0m     logits \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39munembed( residual_stream[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] )\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    273\u001b[0m     top_k_tokens \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mtop_k_tokens( logits, k\u001b[39m=\u001b[39mk )\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/workspace/opt_tools/src/model.py:253\u001b[0m, in \u001b[0;36mModel.get_residual_stream\u001b[0;34m(self, text, input_ids, inputs_embeds, text_activations, verbose, limit, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_residual_stream\u001b[39m( \u001b[39mself\u001b[39m,\n\u001b[1;32m    243\u001b[0m             text: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    244\u001b[0m             input_ids: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    250\u001b[0m         ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m text_activations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m         text_activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_text_activations( text,\n\u001b[1;32m    254\u001b[0m             input_ids, inputs_embeds, verbose, limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs )\n\u001b[1;32m    255\u001b[0m     inpt, attention_out, ff_out, output \u001b[39m=\u001b[39m text_activations\n\u001b[1;32m    257\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(attention_out) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers\n",
      "File \u001b[0;32m~/workspace/opt_tools/src/model.py:220\u001b[0m, in \u001b[0;36mModel.get_text_activations\u001b[0;34m(self, text, input_ids, inputs_embeds, verbose, limit, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inputs_embeds( text, input_ids, verbose, limit )\n\u001b[1;32m    219\u001b[0m \u001b[39m# run the model\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel( inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    221\u001b[0m                       output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs )\n\u001b[1;32m    223\u001b[0m \u001b[39m# get the hidden states\u001b[39;00m\n\u001b[1;32m    224\u001b[0m hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack( outputs\u001b[39m.\u001b[39mhidden_states )\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:786\u001b[0m, in \u001b[0;36mOPTModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    783\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m    785\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m    787\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    788\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    789\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    790\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    791\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    792\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    793\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    794\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    795\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    796\u001b[0m )\n\u001b[1;32m    798\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m    799\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:699\u001b[0m, in \u001b[0;36mOPTDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    690\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    691\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    692\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 699\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    700\u001b[0m         hidden_states,\n\u001b[1;32m    701\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    702\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    703\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    704\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    705\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    706\u001b[0m     )\n\u001b[1;32m    708\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    710\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:330\u001b[0m, in \u001b[0;36mOPTDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions, use_cache, past_key_value)\u001b[0m\n\u001b[1;32m    327\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[1;32m    329\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    331\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    332\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    333\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    334\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    335\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    336\u001b[0m )\n\u001b[1;32m    337\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    338\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:197\u001b[0m, in \u001b[0;36mOPTAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# self_attention\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[0;32m--> 197\u001b[0m     value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_states, value_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FREQ_MULTIPLE = 2\n",
    "\n",
    "for i in range(4):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    data = delete_ff_and_evaluate( opt, FREQ_MULTIPLE )\n",
    "    df = df.append( data, ignore_index=True )\n",
    "    print( df.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(4,8):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    data = delete_ff_and_evaluate( opt, FREQ_MULTIPLE )\n",
    "    df = df.append( data, ignore_index=True )\n",
    "    print( df.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8,12):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    data = delete_ff_and_evaluate( opt, FREQ_MULTIPLE )\n",
    "    df = df.append( data, ignore_index=True )\n",
    "    print( df.T )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
