{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:09:13.779136Z",
     "iopub.status.busy": "2022-11-17T19:09:13.778561Z",
     "iopub.status.idle": "2022-11-17T19:09:16.627942Z",
     "shell.execute_reply": "2022-11-17T19:09:16.626813Z",
     "shell.execute_reply.started": "2022-11-17T19:09:13.779072Z"
    }
   },
   "outputs": [],
   "source": [
    "try: # if in google colab, download necessary python files\n",
    "  import google.colab\n",
    "  ! git clone https://github.com/pesvut/opt-tools.git && mv ./opt-tools/src/*.py .\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "! pip install -qq transformers datasets evaluate zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:09:16.629696Z",
     "iopub.status.busy": "2022-11-17T19:09:16.629473Z",
     "iopub.status.idle": "2022-11-17T19:09:21.172835Z",
     "shell.execute_reply": "2022-11-17T19:09:21.172071Z",
     "shell.execute_reply.started": "2022-11-17T19:09:16.629672Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from texts import prepare_pile, prepare_code\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:09:21.174232Z",
     "iopub.status.busy": "2022-11-17T19:09:21.173782Z",
     "iopub.status.idle": "2022-11-17T19:17:46.248669Z",
     "shell.execute_reply": "2022-11-17T19:17:46.247971Z",
     "shell.execute_reply.started": "2022-11-17T19:09:21.174207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a6739037a040ac85d9f8949823d4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6764236c6e8c42598cc24367c619271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e30deb19da94f2e9c7017aed33ef552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcae952f6c8f4d7fb10bad71cef176a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/721 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2078312d0f4a4e14a3797ff93a14e85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/719 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15e5eaa17f14702b7f90d0f07db021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0aa438d7dd4b05b7e01036d8bf69a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.29G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beb6cf9106c4d5a9c85ab9802c238a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1657cc9f3e840b5a6403c8fcf9dc3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded OPT-None\n",
      " - Registered 40 OPT Attention Layers\n"
     ]
    }
   ],
   "source": [
    "def prepare( dataset_name ):\n",
    "    if dataset_name == 'pile':\n",
    "        return prepare_pile()\n",
    "    if dataset_name == 'code':\n",
    "        return prepare_code()\n",
    "\n",
    "opt = Model(\"13b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:17:46.250509Z",
     "iopub.status.busy": "2022-11-17T19:17:46.250272Z",
     "iopub.status.idle": "2022-11-17T19:17:46.254666Z",
     "shell.execute_reply": "2022-11-17T19:17:46.254052Z",
     "shell.execute_reply.started": "2022-11-17T19:17:46.250487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTDecoderLayer(\n",
      "  (self_attn): OPTAttention(\n",
      "    (k_proj): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "    (v_proj): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "    (q_proj): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "    (out_proj): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "  )\n",
      "  (activation_fn): ReLU()\n",
      "  (self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=5120, out_features=20480, bias=True)\n",
      "  (fc2): Linear(in_features=20480, out_features=5120, bias=True)\n",
      "  (final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( opt.model.decoder.layers[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:17:46.255640Z",
     "iopub.status.busy": "2022-11-17T19:17:46.255430Z",
     "iopub.status.idle": "2022-11-17T19:17:46.268862Z",
     "shell.execute_reply": "2022-11-17T19:17:46.268220Z",
     "shell.execute_reply.started": "2022-11-17T19:17:46.255620Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def setup_counter(ff_keys):\n",
    "    shape = ff_keys.size()\n",
    "    counter = []\n",
    "    for i in range(shape[0]):\n",
    "        counter.append( torch.zeros( shape[-1]))\n",
    "    return torch.stack(counter).to( opt.device )\n",
    "\n",
    "def count_keys( dataset_name, limit=1000, sample_size=10000, num_samples=1, \n",
    "                check_accuracy=False, k=10, check_skips=False ):\n",
    "    dataset, label, skip_eval = prepare( dataset_name )\n",
    "    counters = []\n",
    "    counter = None\n",
    "    curr_count = 0\n",
    "    with tqdm(total=sample_size*num_samples) as pbar:\n",
    "        for data in dataset:\n",
    "            text = data[label]\n",
    "            input_ids = opt.get_ids( text, limit=limit )\n",
    "            ids = input_ids.squeeze().detach().cpu()\n",
    "\n",
    "            # Criteria for counting the token activation\n",
    "            criteria = torch.ones_like( ids, dtype=torch.bool )\n",
    "\n",
    "            # check if prediction is accurate enough to count\n",
    "            if check_accuracy:\n",
    "                residual_stream = opt.get_residual_stream( input_ids=input_ids )\n",
    "                logits = opt.unembed( residual_stream[-1] ).detach().cpu()\n",
    "                top_k_tokens = opt.top_k_tokens( logits, k=k ).squeeze()\n",
    "\n",
    "                for index in range(len(ids)-1):\n",
    "                    criteria[index] *= (ids[index+1] in top_k_tokens[index])\n",
    "\n",
    "            # Choose a set of token ids to skip \n",
    "            if check_skips:\n",
    "                skip_ids = set()\n",
    "                for skip_string in skip_eval:\n",
    "                    skip_id = int( opt.get_ids( skip_string ).squeeze()[-1] )\n",
    "                    skip_ids.add( skip_id )\n",
    "\n",
    "                for index in range(len(ids)-1):\n",
    "                    criteria[index] *= (ids[index+1] in skip_ids)\n",
    "                \n",
    "            num_valid_tokens = criteria.sum()\n",
    "            curr_count += num_valid_tokens\n",
    "\n",
    "            ff_keys = opt.get_ff_key_activations(input_ids=input_ids)\n",
    "            if counter is None:\n",
    "                counter = setup_counter(ff_keys)\n",
    "            \n",
    "            for layer_index, layer in enumerate(ff_keys):\n",
    "                for token_index, key_activation in enumerate(layer):\n",
    "                    if not criteria[token_index]:\n",
    "                        continue\n",
    "                    counter[layer_index] += ( key_activation != 0 )\n",
    "\n",
    "\n",
    "            pbar.update( int(num_valid_tokens) )\n",
    "            if curr_count > sample_size:\n",
    "                counter = counter / curr_count\n",
    "                counters.append( counter.detach().cpu() )\n",
    "                print( f'sample {len(counters)}: {curr_count}' )\n",
    "                \n",
    "                counter = setup_counter(ff_keys)\n",
    "                curr_count = 0\n",
    "            \n",
    "            if len( counters ) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    return torch.stack( counters )\n",
    "\n",
    "def acc_str( acc, pred ):\n",
    "    percentage = (100*round(acc/pred, 3))\n",
    "    return \"%.1f\"%percentage + \"% - ( {acc}/{pred} )\"\n",
    "\n",
    "def evaluate( dataset_name, limit : int = 1e6 ):\n",
    "    dataset, label, skip_eval = prepare( dataset_name )\n",
    "    out = opt.evaluate_dataset( dataset, token_limit=1000, k=1,\n",
    "        start_index=1, stopping_index=limit, skip_eval=skip_eval,\n",
    "        dataset_text_label=label, count_tokens=False )\n",
    "    print( f'{dataset_name} w/ skip:', \n",
    "        acc_str(out['num_skip_accurate'], out['num_skip_predictions']) )\n",
    "    print( f'{dataset_name} no skip:',\n",
    "        acc_str( out['num_accurate'], out['num_predictions']) )\n",
    "    return out\n",
    "\n",
    "def evaluate_all( limit: int = 1e5 ):\n",
    "    pile_out = evaluate( 'pile', limit )\n",
    "    code_out = evaluate( 'code', limit )\n",
    "\n",
    "def delete_and_evaluate(\n",
    "        freq_multiple: float,\n",
    "        counter_sample_size: int = 5e4,\n",
    "        eval_sample_size: int = 1e5,\n",
    "        ):\n",
    "    # Count activation of MLP middle layers\n",
    "    pile_counters = count_keys( 'pile', sample_size=counter_sample_size, num_samples=1, check_accuracy=True )\n",
    "    code_counters = count_keys( 'code', sample_size=counter_sample_size, num_samples=1, check_accuracy=True )\n",
    "    \n",
    "    # Delete when the MLP layer activates way more for code than pile\n",
    "    ff_criterion = ( code_counters[0] > (freq_multiple*pile_counters[0]) )\n",
    "    sums = [ x.sum() for x in ff_criterion.detach().numpy() ]\n",
    "    print( \"%5d -\"%np.sum(sums), sums )\n",
    "    opt.delete_ff_keys( ff_criterion )\n",
    "    \n",
    "    try:\n",
    "        # Save the indices that were deleted into the timestamped file\n",
    "        print(\"saving file...\")\n",
    "        now = datetime.datetime.now().strftime( \"%Y-%m-%d_%H:%M:%S\" )\n",
    "        filename = f'tmp/{opt.model_size}-{freq_multiple}x-{now}.npy'\n",
    "        os.makedirs( 'tmp', exist_ok=True )\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.save(f, np.array(ff_criterion) )\n",
    "        print(\"saved successfully\")\n",
    "    except Exception:\n",
    "        print(\"Did not save sadly :(\")\n",
    "\n",
    "    \n",
    "    # See the effect this has on performance\n",
    "    evaluate_all( eval_sample_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:17:46.269741Z",
     "iopub.status.busy": "2022-11-17T19:17:46.269552Z",
     "iopub.status.idle": "2022-11-17T19:17:47.528642Z",
     "shell.execute_reply": "2022-11-17T19:17:47.527996Z",
     "shell.execute_reply.started": "2022-11-17T19:17:46.269722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8985 - [720, 437, 1103, 621, 621, 662, 670, 466, 310, 382, 401, 328, 298, 209, 172, 130, 27, 24, 22, 34, 77, 83, 58, 35, 43, 27, 41, 52, 39, 44, 59, 49, 102, 127, 90, 79, 121, 112, 110]\n",
      " 6518 - [42, 65, 176, 634, 551, 1162, 802, 644, 277, 336, 336, 254, 447, 119, 94, 98, 23, 34, 19, 19, 44, 28, 43, 25, 12, 11, 7, 12, 9, 11, 16, 19, 26, 21, 15, 28, 22, 21, 16]\n",
      " 5523 - [103, 70, 100, 211, 439, 1068, 447, 294, 383, 174, 255, 245, 277, 286, 128, 78, 32, 138, 90, 88, 124, 86, 85, 59, 25, 17, 8, 9, 14, 17, 9, 11, 6, 11, 17, 20, 22, 33, 44]\n",
      " 8985 - [720, 437, 1103, 621, 621, 662, 670, 466, 310, 382, 401, 328, 298, 209, 172, 130, 27, 24, 22, 34, 77, 83, 58, 35, 43, 27, 41, 52, 39, 44, 59, 49, 102, 127, 90, 79, 121, 112, 110]\n",
      " 4745 - [21, 22, 40, 208, 1081, 540, 399, 574, 155, 80, 179, 164, 353, 277, 104, 104, 17, 81, 93, 13, 37, 27, 23, 14, 9, 10, 8, 4, 3, 5, 5, 6, 6, 9, 11, 16, 14, 14, 19]\n",
      " 5523 - [103, 70, 100, 211, 439, 1068, 447, 294, 383, 174, 255, 245, 277, 286, 128, 78, 32, 138, 90, 88, 124, 86, 85, 59, 25, 17, 8, 9, 14, 17, 9, 11, 6, 11, 17, 20, 22, 33, 44]\n",
      " 4685 - [161, 169, 233, 259, 652, 834, 387, 270, 227, 272, 124, 168, 175, 145, 32, 17, 21, 29, 64, 49, 93, 76, 63, 53, 15, 10, 3, 10, 7, 9, 8, 6, 7, 9, 7, 1, 5, 6, 9]\n",
      " 3716 - [112, 143, 216, 234, 333, 536, 391, 217, 183, 115, 184, 133, 173, 83, 47, 17, 13, 37, 64, 42, 84, 56, 82, 47, 21, 11, 8, 12, 6, 14, 11, 15, 10, 5, 8, 6, 16, 13, 18]\n",
      " 2059 - [38, 52, 87, 124, 193, 425, 217, 156, 67, 72, 71, 45, 56, 67, 5, 5, 5, 14, 38, 34, 54, 41, 39, 58, 36, 13, 5, 15, 5, 6, 3, 2, 0, 2, 3, 2, 1, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "pre_removals = [\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_14:15:52.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_16:13:26.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_17:05:07.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_15:47:29.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_16:38:41.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_17:05:07.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_18:02:52.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_18:31:52.npy\",\n",
    "    \"/notebooks/src/tmp/13b-3.9x-2022-11-17_19:01:42.npy\",\n",
    "]\n",
    "\n",
    "for filename in pre_removals:\n",
    "    ff_criterion = np.load(filename)\n",
    "    sums = [ x.sum() for x in ff_criterion ]\n",
    "    print( \"%5d -\"%np.sum(sums), sums )\n",
    "    opt.delete_ff_keys( ff_criterion )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:17:47.529771Z",
     "iopub.status.busy": "2022-11-17T19:17:47.529540Z",
     "iopub.status.idle": "2022-11-17T19:29:29.456218Z",
     "shell.execute_reply": "2022-11-17T19:29:29.455577Z",
     "shell.execute_reply.started": "2022-11-17T19:17:47.529749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e17cba58314c7b9ddc2c2d3c7d207d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n",
      "accuracy 45.5% (curr 37.0%): : 100396it [04:45, 351.32it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile w/ skip: 45.5% - ( {acc}/{pred} )\n",
      "pile no skip: 51.0% - ( {acc}/{pred} )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-d84b00ddcc43747c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/codeparrot--codeparrot-clean-valid to /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-d84b00ddcc43747c/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1863e452774a82953c6c7888289343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15429877771949eebf3c53d5c833bae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e845d03eb44aab4071c4a6b443648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff526f004e2b402a869419edc1f6781e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-d84b00ddcc43747c/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd798a2a6d714f01a23bcffba319a8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy 42.0% (curr 52.7%): : 100420it [06:49, 245.41it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code w/ skip: 42.0% - ( {acc}/{pred} )\n",
      "code no skip: 32.1% - ( {acc}/{pred} )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model before removal of any neurons\n",
    "evaluate_all( 1e5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T19:29:29.458648Z",
     "iopub.status.busy": "2022-11-17T19:29:29.458440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- RUNNING RUN No 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941240abb7f84bbda69e2c98ea912744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: 50184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-d84b00ddcc43747c\n",
      "Reusing dataset json (/root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-d84b00ddcc43747c/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20368f17934c49a9a5a4afbf16005a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76124f359eaf4c568717b87f2db14e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: 50215\n",
      " 1018 - [2, 6, 18, 30, 97, 256, 139, 49, 20, 34, 19, 34, 25, 43, 0, 2, 2, 11, 29, 21, 15, 38, 37, 14, 49, 5, 4, 3, 6, 3, 2, 0, 0, 1, 1, 0, 1, 0, 2]\n",
      "saving file...\n",
      "saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n",
      "accuracy 45.5% (curr 37.0%): : 100396it [04:44, 352.38it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile w/ skip: 45.5% - ( {acc}/{pred} )\n",
      "pile no skip: 51.0% - ( {acc}/{pred} )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-d84b00ddcc43747c\n",
      "Reusing dataset json (/root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-d84b00ddcc43747c/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d786c0a744e6abddaf4fe316d56d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy 42.0% (curr 52.4%): : 100420it [06:51, 244.17it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code w/ skip: 42.0% - ( {acc}/{pred} )\n",
      "code no skip: 32.1% - ( {acc}/{pred} )\n",
      "\n",
      "\n",
      "- RUNNING RUN No 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47393e677c84494ba733fa64c7f9ef83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: 50173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration codeparrot--codeparrot-clean-valid-d84b00ddcc43747c\n",
      "Reusing dataset json (/root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-valid-d84b00ddcc43747c/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd26f40da0de487a96e5269ed481e813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b1dd8b024646c08cf6ce55ca1aa652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FREQ_MULTIPLE = 3.9\n",
    "\n",
    "for i in range(4):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    delete_and_evaluate( FREQ_MULTIPLE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print('\\n\\n- RUNNING RUN No', i )\n",
    "    delete_and_evaluate( FREQ_MULTIPLE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#for layer in range(len(code_counters[0])):\n",
    "#    plt.figure()\n",
    "#    subsample = 1000\n",
    "#    plt.plot(code_counters[0][layer][:subsample], color='red', linewidth=0.2)\n",
    "#    plt.plot(pile_counters[0][layer][:subsample], color='blue', linewidth=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 1e4 steps\n",
    "```\n",
    "pile w/ skip: 39.0% - ( 4022/10381 )\n",
    "pile no skip: 49.0% - ( 8109/16445 )\n",
    "\n",
    "code w/ skip: 43.0% - ( 4381/10209 )\n",
    "code no skip: 60.0% - ( 12974/21528)\n",
    "```\n",
    "\n",
    "After 1 iteration:\n",
    "```\n",
    "pile w/ skip: 36.0% - ( 3702/10381 )\n",
    "pile no skip: 46.0% - ( 7573/16445 )\n",
    "\n",
    "code w/ skip: 35.0% - ( 3620/10209 )\n",
    "code no skip: 50.0% - ( 10818/21528 )\n",
    "```\n",
    "\n",
    "After 3 iterations:\n",
    "```\n",
    "pile w/ skip: 31.0% - ( 3249/10381 )\n",
    "pile no skip: 43.0% - ( 7007/16445 )\n",
    "\n",
    "code w/ skip: 21.0% - ( 2108/10209 )\n",
    "code no skip: 37.0% - ( 7970/21528 )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
