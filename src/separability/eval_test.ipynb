{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from separability import Model\n",
    "from datasets import load_dataset, get_dataset_config_names\n",
    "\n",
    "m = Model(\"facebook/opt-125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract_algebra\n",
      "{'percentage_correct': 0.24210526315789474}\n",
      "anatomy\n",
      "{'percentage_correct': 0.3384615384615385}\n",
      "astronomy\n",
      "{'percentage_correct': 0.29931972789115646}\n",
      "business_ethics\n",
      "{'percentage_correct': 0.05263157894736842}\n",
      "clinical_knowledge\n",
      "{'percentage_correct': 0.2653846153846154}\n",
      "college_biology\n",
      "{'percentage_correct': 0.19424460431654678}\n",
      "college_chemistry\n",
      "{'percentage_correct': 0.12631578947368421}\n",
      "college_computer_science\n",
      "{'percentage_correct': 0.21052631578947367}\n",
      "college_mathematics\n",
      "{'percentage_correct': 0.30526315789473685}\n",
      "college_medicine\n",
      "{'percentage_correct': 0.23809523809523808}\n",
      "college_physics\n",
      "{'percentage_correct': 0.1958762886597938}\n",
      "computer_security\n",
      "{'percentage_correct': 0.2631578947368421}\n",
      "conceptual_physics\n",
      "{'percentage_correct': 0.30869565217391304}\n",
      "econometrics\n",
      "{'percentage_correct': 0.12844036697247707}\n",
      "electrical_engineering\n",
      "{'percentage_correct': 0.3}\n",
      "elementary_mathematics\n",
      "{'percentage_correct': 0.23324396782841822}\n",
      "formal_logic\n",
      "{'percentage_correct': 0.19834710743801653}\n",
      "global_facts\n",
      "{'percentage_correct': 0.3157894736842105}\n",
      "high_school_biology\n",
      "{'percentage_correct': 0.2360655737704918}\n",
      "high_school_chemistry\n",
      "{'percentage_correct': 0.2676767676767677}\n",
      "high_school_computer_science\n",
      "{'percentage_correct': 0.3263157894736842}\n",
      "high_school_european_history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [526,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m mmlu_configs():\n\u001b[0;32m--> 112\u001b[0m     out \u001b[39m=\u001b[39m evaluate_mmlu(m, c)\n\u001b[1;32m    113\u001b[0m     \u001b[39mprint\u001b[39m(out[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[60], line 80\u001b[0m, in \u001b[0;36mevaluate_mmlu\u001b[0;34m(opt, config, n_shot)\u001b[0m\n\u001b[1;32m     77\u001b[0m input_ids \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mget_ids(text)\n\u001b[1;32m     79\u001b[0m \u001b[39m# Get the guess (logits of the last token)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m all_logits \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mget_all_logits(input_ids)\n\u001b[1;32m     81\u001b[0m logits \u001b[39m=\u001b[39m all_logits[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m     82\u001b[0m guess \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode(logits\u001b[39m.\u001b[39margmax())\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/separability/src/separability/model.py:849\u001b[0m, in \u001b[0;36mModel.get_all_logits\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_logits\u001b[39m( \u001b[39mself\u001b[39m, input_ids ):\n\u001b[1;32m    847\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get output logits from input token ids\"\"\"\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel( input_ids, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m )\n\u001b[1;32m    850\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munembed( outputs\u001b[39m.\u001b[39mlast_hidden_state )\n\u001b[1;32m    852\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:795\u001b[0m, in \u001b[0;36mOPTModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    792\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m    794\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m    796\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    797\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    798\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    799\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    800\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    801\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    802\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    803\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    804\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    805\u001b[0m )\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m    808\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:710\u001b[0m, in \u001b[0;36mOPTDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    702\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    703\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    704\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    708\u001b[0m     )\n\u001b[1;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    711\u001b[0m         hidden_states,\n\u001b[1;32m    712\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mcausal_attention_mask,\n\u001b[1;32m    713\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    714\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    715\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    716\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    717\u001b[0m     )\n\u001b[1;32m    719\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:330\u001b[0m, in \u001b[0;36mOPTDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    327\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[1;32m    329\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    331\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    332\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    333\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    334\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    335\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    336\u001b[0m )\n\u001b[1;32m    337\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    338\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:225\u001b[0m, in \u001b[0;36mOPTAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttention mask should be of size \u001b[39m\u001b[39m{\u001b[39;00m(bsz,\u001b[39m \u001b[39m\u001b[39m1\u001b[39m,\u001b[39m \u001b[39mtgt_len,\u001b[39m \u001b[39msrc_len)\u001b[39m}\u001b[39;00m\u001b[39m, but is \u001b[39m\u001b[39m{\u001b[39;00mattention_mask\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len) \u001b[39m+\u001b[39m attention_mask\n\u001b[1;32m    224\u001b[0m     attn_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(\n\u001b[0;32m--> 225\u001b[0m         attn_weights, torch\u001b[39m.\u001b[39;49mtensor(torch\u001b[39m.\u001b[39;49mfinfo(attn_weights\u001b[39m.\u001b[39;49mdtype)\u001b[39m.\u001b[39;49mmin, device\u001b[39m=\u001b[39;49mattn_weights\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[1;32m    229\u001b[0m \u001b[39m# upcast to fp32 if the weights are in fp16. Please see https://github.com/huggingface/transformers/pull/17437\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from welford_torch import Welford\n",
    "\n",
    "mcq_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def format_mmlu_question(datum, include_answer=False):\n",
    "    s  = \"Question:\\n\"\n",
    "    s += datum[\"question\"]\n",
    "    s += \"\\n\\n\"\n",
    "    s += \"Choices:\"\n",
    "    for index, choice in enumerate(datum[\"choices\"]):\n",
    "        s += f\"\\n{mcq_letters[index]}) {choice}\"\n",
    "    s += \"\\n\\n\"\n",
    "    s += \"Answer: \"\n",
    "    if include_answer:\n",
    "        s += mcq_letters[datum[\"answer\"]]\n",
    "    return s\n",
    "\n",
    "def mmlu_configs():\n",
    "    return get_dataset_config_names(\"tasksource/mmlu\")\n",
    "\n",
    "def evaluate_mmlu(\n",
    "        opt: Model,\n",
    "        config: Union[str, List[str]] = None,\n",
    "        n_shot: int = 5,\n",
    "    ):\n",
    "    config_options = mmlu_configs()\n",
    "    error_string = f\" Config must be either 'all' or one/list of {config_options}\"\n",
    "\n",
    "    if config is None:\n",
    "        raise ValueError(\"Must specify a config.\" + error_string)\n",
    "\n",
    "    if isinstance(config, str):\n",
    "        if config == \"all\":\n",
    "            config = config_options\n",
    "        elif config in config_options:\n",
    "            config = [config]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid config: {config}.\" + error_string)\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for c in config:\n",
    "        _dataset = load_dataset(\"tasksource/mmlu\", c)[\"test\"]\n",
    "\n",
    "        # Create a pre-prompt with the first n_shot examples\n",
    "        initial_prompt = \"\"\n",
    "        for i in range(n_shot):\n",
    "            initial_prompt += format_mmlu_question(_dataset[i], include_answer=True)\n",
    "            initial_prompt += \"\\n\\n\"\n",
    "\n",
    "        # Remove the first n_shot examples from the dataset \n",
    "        indices = list(range(n_shot, len(_dataset))) \n",
    "        _dataset = _dataset.select(indices=indices)\n",
    "        \n",
    "        tasks.append((initial_prompt, _dataset, c))\n",
    "\n",
    "    # Store accuracy and losses\n",
    "    out = {\n",
    "        \"num_predictions\": 0,\n",
    "        \"num_accurate\": 0,\n",
    "        \"num_skip_predictions\": 0,\n",
    "        \"num_skip_accurate\": 0,\n",
    "        \"num_topk_accurate\": 0,\n",
    "        \"num_topk_skip_accurate\": 0,\n",
    "        \"token_counts\": None,\n",
    "    }\n",
    "    loss_tracker = Welford() \n",
    "\n",
    "    for initial_prompt, _dataset, dataset_name in tasks:\n",
    "        print(dataset_name)\n",
    "        for datum in _dataset:\n",
    "            # Prepare text\n",
    "            text = initial_prompt + \\\n",
    "                format_mmlu_question(datum, True)\n",
    "            input_ids = opt.get_ids(text)\n",
    "           \n",
    "            # Get the guess (logits of the last token)\n",
    "            all_logits = opt.get_all_logits(input_ids)\n",
    "            logits = all_logits[0, -2]\n",
    "            guess = opt.tokenizer.decode(logits.argmax()).strip()\n",
    "            truth = mcq_letters[datum[\"answer\"]]\n",
    "            \n",
    "            # Compare to ground truth\n",
    "            loss = opt.evaluate_ce_loss(\n",
    "                input_ids=input_ids[0, -2:].unsqueeze(0),\n",
    "                logits=all_logits[0, -2:].unsqueeze(0),\n",
    "            )\n",
    "            \n",
    "            out[\"num_predictions\"] += 1\n",
    "            out[\"num_accurate\"] += int(guess == truth)\n",
    "            loss_tracker.add( loss.detach() )\n",
    "        \n",
    "        \n",
    "    loss = loss_tracker.mean.cpu().numpy()\n",
    "    log_loss = np.log(loss)\n",
    "        \n",
    "    out.update({\n",
    "        \"accuracy\": {\n",
    "            \"percentage_correct\": out[\"num_accurate\"] / out[\"num_predictions\"],\n",
    "        },\n",
    "        \"loss_data\": {\n",
    "            \"loss\": loss,\n",
    "            \"log_loss\": np.log(loss)\n",
    "        },\n",
    "    })\n",
    "    \n",
    "    return out\n",
    "\n",
    "for c in mmlu_configs():\n",
    "    out = evaluate_mmlu(m, c)\n",
    "    print(out[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/separability/src/separability/model.py:106: UserWarning: Model openlm-research/open_llama_3b_v2 not tested.\n",
      "  warnings.warn( f\"Model {model_repo} not tested.\" )\n",
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[39m=\u001b[39m Model(\u001b[39m\"\u001b[39;49m\u001b[39mopenlm-research/open_llama_3b_v2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m mmlu_configs():\n\u001b[1;32m      4\u001b[0m     out \u001b[39m=\u001b[39m evaluate_mmlu(m, c)\n",
      "File \u001b[0;32m~/separability/src/separability/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model_repo, limit, model_device, output_device, use_accelerator, dtype, torch_dtype, svd_attn)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m model_device \u001b[39mif\u001b[39;00m model_device \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device \u001b[39m=\u001b[39m output_device \u001b[39mif\u001b[39;00m output_device \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 95\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_model( model_repo )\n\u001b[1;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlimit \u001b[39m=\u001b[39m limit\n\u001b[1;32m     98\u001b[0m \u001b[39m# Indices of outputs for reference\u001b[39;00m\n",
      "File \u001b[0;32m~/separability/src/separability/model.py:133\u001b[0m, in \u001b[0;36mModel.init_model\u001b[0;34m(self, model_repo)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap\u001b[39m.\u001b[39mlayers\n\u001b[1;32m    132\u001b[0m \u001b[39m#self.predictor = OPTForCausalLM.from_pretrained(self.repo, dtype=self.dtype)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    135\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m- Loaded \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_repo\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivations \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/separability/src/separability/model.py:161\u001b[0m, in \u001b[0;36mModel.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mto( device )\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mto( device )\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:1900\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1896\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1898\u001b[0m     )\n\u001b[1;32m   1899\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/separability/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "m = Model(\"openlm-research/open_llama_3b_v2\")\n",
    "print(m)\n",
    "\n",
    "for c in mmlu_configs():\n",
    "    out = evaluate_mmlu(m, c)\n",
    "    print(out[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
